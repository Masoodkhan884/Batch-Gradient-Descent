# Batch-Gradient-Descent
Batch Gradient Descent is an optimization algorithm used in machine learning to minimize a cost function. It computes the gradient of the cost function with respect to the parameters by averaging over the entire dataset, then updates the parameters in the opposite direction of the gradient to converge to the global minimum.
